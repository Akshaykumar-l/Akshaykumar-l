{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4801f0",
   "metadata": {},
   "source": [
    "# 1. Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db470a",
   "metadata": {},
   "source": [
    "## Assumptions for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d33564",
   "metadata": {},
   "source": [
    "1.Data should be Linear -------------------------------(We can check by scatter plot) <br>\n",
    "2.There should not be any multi-coolinearity ----------(Variance inflation Factor (VIF)) <br>\n",
    "3.There should not be any auto corelation ------------- Durban Watson Test <br>\n",
    "4.There should not be any HeteroScadacity <br>\n",
    "5.Residual should be normally distributed <br>\n",
    "6.There should not be any endogeniaty problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90089077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(x_train,y_train)\n",
    "model_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.intercept_\n",
    "model_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf489e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = model_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58858b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = (var(mean)-var(line))/var(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00e565",
   "metadata": {},
   "source": [
    "1.The results from r2_score(y_test,y_pred) is equal to model.score(x_test,y_test) <br>\n",
    "2. R2 value tells us the strength of relationship between two variables. <br>\n",
    "3. if R2 is 0.9 then it means 90% of the variation in the data is explained by the model <br>\n",
    "4. if R2 is something like 0.1 then it means only 10% of the variation in the data is explained by model other \n",
    " remaining 90% is explained by something else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d5c46",
   "metadata": {},
   "source": [
    "## 2.Ordinary Least Square Method (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b73957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.regression.linear_model as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ols = smf.OLS(endog=y_train,exog=X_train).fit()\n",
    "model_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94baed85",
   "metadata": {},
   "source": [
    "## <b><font color ='Green'>Homoscedasticity:</b></font> Linear regression assumes that the <b><font color='Red'>variance of the errors</b><font> is constant across all levels of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4e9be",
   "metadata": {},
   "source": [
    "### <b><font color='Blue'>Normality of errors</b><font>: Linear regression assumes that the <b><font color='black'>errors</b><font> are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality\n",
    "plt.scatter(y_test, y_pred)\n",
    "\n",
    "# Checking Normality of Redidual with distribution plot\n",
    "sns.distplot((y_test - y_pred), bins=50)\n",
    "\n",
    "# Same thing as above\n",
    "delta = y_test - y_pred # residual \n",
    "sns.set_style('whitegrid')\n",
    "sns.kdeplot(np.array(delta), bw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8efa462",
   "metadata": {},
   "source": [
    "1.Why we use square loss function but not absolute loss function in linear regression? <br>\n",
    "Ans. Absolute loss function (|y_pred-y_actua|) is not differentiable at 0. and we find best fit line by minimizing error <br>\n",
    "the function should differentiable at all points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5cb0a",
   "metadata": {},
   "source": [
    "### VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variable = x_scaler\n",
    "vif = pd.DataFrame()\n",
    "vif['Variance Inflation Factor'] = [variance_inflation_factor(variable, i) \n",
    "                                    for i in range(variable.shape[1])]\n",
    "vif['Features'] = x.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7dbc1",
   "metadata": {},
   "source": [
    "### Regularisation method to handle overfitting problem\n",
    "\n",
    "1.Ridge (L2)<br>\n",
    "2.Lasso (L1)<br>\n",
    "3.ElasticNet(Ridge + Lasso)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34715b04",
   "metadata": {},
   "source": [
    "## Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=0.1)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "y_pred_ridge = ridge_reg.predict(x_test)\n",
    "r2_score(y_test, y_pred_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9bd18",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "y_pred_lasso = lasso_reg.predict(x_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47284d7",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_reg = ElasticNet(alpha=0.1,l1_ratio=0.5)\n",
    "elastic_reg.fit(x_train, y_train)\n",
    "y_pred_elastic = elastic_reg.predict(x_test)\n",
    "r2_score(y_test, y_pred_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8bada",
   "metadata": {},
   "source": [
    "# model measurement \n",
    " 1) MSE\n",
    " 2) RMSE\n",
    " 3) MAE\n",
    " 4) MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33dab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0feb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE', metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('RMSE', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('MAE', metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "print('MAPE', metrics.mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae54ee",
   "metadata": {},
   "source": [
    "## Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e4e15",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm that is commonly used in machine learning to find the values of parameters <br> \n",
    "(such as the coefficients in a linear regression model) that minimize a cost function. <br> \n",
    "The cost function represents the error or difference between the predicted values and the actual values,<br> \n",
    "and the goal of gradient descent is to find the parameter values that minimize this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f891b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd= SGDRegressor()\n",
    "sgd.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfca129",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd = sgd.predict(x_test)\n",
    "r2_score(y_test, y_pred_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b748319",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c55f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3028d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "x_train_trans = poly.fit_transform(x_train2)\n",
    "x_test_trans = poly.fit_transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6eedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_poly = LinearRegression()\n",
    "linear_poly.fit(x_train_trans, y_train2)\n",
    "y_pred_ply = linear_poly.predict(x_test_trans)\n",
    "r2_score(y_test2,y_pred_ply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54737355",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6009d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_model = LogisticRegression()\n",
    "logit_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a40f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict result\n",
    "y_pred_train = logit_model.predict(x_train)\n",
    "y_pred_test = logit_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f0743",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46941e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_test)\n",
    "confusion_matrix(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_test))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred_test)\n",
    "accuracy_score(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "logistic_roc_auc = roc_auc_score(y_test,y_pred_test)\n",
    "logistic_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "#fpr-False Positive rate \n",
    "#tpr-True Positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = \"ROC Curve (area=%0.2f)\" %logistic_roc_auc)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic with Area Under Curve\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581897a",
   "metadata": {},
   "source": [
    "###  How to improve my model-KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64764278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation score - K_FOLD method\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy = cross_val_score(logit_model, x_test, y_test, cv =20)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d562bc2",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ede3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt1 = DecisionTreeClassifier(criterion='gini')\n",
    "dt1.fit(x_train, y_train)\n",
    "dt2 = DecisionTreeClassifier(criterion='entropy')\n",
    "dt2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_pred_dt1_train = dt1.predict(x_train)\n",
    "y_pred_dt1_test = dt1.predict(x_test)\n",
    "\n",
    "y_pred_dt2_train = dt2.predict(x_train)\n",
    "y_pred_dt2_test = dt2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post pruning\n",
    "dt1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index=x.columns, data=dt1.feature_importances_, columns = ['Feature Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe593882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dt1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "plot_tree(dt2, feature_names=x.columns, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9123462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter in DecisionTree\n",
    "prunned_tree = DecisionTreeClassifier(max_depth=2)\n",
    "prunned_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdc15f",
   "metadata": {},
   "source": [
    "## Random Forest and Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6744f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest and Bagging method\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier()\n",
    "bag.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bag_train = bag.predict(x_train)\n",
    "y_pred_bag_test = bag.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40474f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=2,oob_score=True)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ba633",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_train = rf.predict(x_train)\n",
    "y_pred_rf_test = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d8e7b",
   "metadata": {},
   "source": [
    "## Boosting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af401e04",
   "metadata": {},
   "source": [
    "## 1. Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38957aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=50,random_state=101)\n",
    "ada.fit(x_train,y_train)\n",
    "y_pred = ada.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c09718",
   "metadata": {},
   "source": [
    "## 2.Gradient Boost Decision Tree (GBDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48819475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "gbc.fit(x_train,y_train)\n",
    "y_pred = gbc.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42f20c",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a949bf7",
   "metadata": {},
   "source": [
    "## 4. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier()\n",
    "cat.fit(x_train,y_train)\n",
    "cat.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eebf1b",
   "metadata": {},
   "source": [
    "## 5. lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09914be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgbc = lgb.LGBMClassifier()\n",
    "lgbc.fit(x_train,y_train)\n",
    "lgbc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345fb4a",
   "metadata": {},
   "source": [
    "## 6. HistGradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hist = HistGradientBoostingClassifier()\n",
    "hist.fit(x_train,y_train)\n",
    "hist.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d70e8",
   "metadata": {},
   "source": [
    "## 4. Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d458810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262b4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = LogisticRegression()\n",
    "cl2 = KNeighborsClassifier()\n",
    "cl3 = GaussianNB()\n",
    "cl4 = RandomForestClassifier()\n",
    "cl5 = XGBClassifier()\n",
    "sclf = StackingClassifier(classifiers=[cl2,cl3,cl4,cl5],meta_classifier=cl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5-fold cross validation :\\n')\n",
    "for clf ,label in zip([cl2,cl3,cl4,cl5,sclf],['KNeighborsClassifier','GuassianNB','RandomForestClassifier','XGBClassifier',\n",
    "                                            'StackingClassifier']):\n",
    "    scores = cross_val_score(clf,x_train,y_train,cv=20,scoring='accuarcy')\n",
    "    print(\"Accuracy : %0.2f (+/-%0.2f)[%s]\" %(scores.mean(),scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83937",
   "metadata": {},
   "source": [
    "## 5.Isolation Forest , LocalOutlierFactor,OneClassSvm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a70df",
   "metadata": {},
   "source": [
    " ISOLATION FOREST, Local Outlier Factor , OneClassSVM - These models dedicated for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf1244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea10254",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {'IsolationForest' : IsolationForest(n_estimators=100,max_samples=len(x_train), \n",
    "                                                    contamination= fraudlent_transaction),\n",
    "                 \n",
    "                 \"LocalOutlierFactor\" : LocalOutlierFactor(n_neighbors=20, contamination=fraudlent_transaction),\n",
    "                 \"OneClassSVM\" : OneClassSVM()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolaction.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604e5bc",
   "metadata": {},
   "source": [
    "# Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2f2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c4a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ac598",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf = setup(data=train_data,target='target_column_name',session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e214e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44924b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = create_model('gbc') ## if we find Gradient Descent is best from above compare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
